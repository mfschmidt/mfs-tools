{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-13T02:00:11.808887Z",
     "start_time": "2025-03-13T02:00:09.778052Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import h5py\n",
    "import nibabel as nib\n",
    "from datetime import datetime\n",
    "\n",
    "from mfs_tools.library.utility_stuff import (\n",
    "    correlate_bold, compare_mats\n",
    ")\n",
    "from mfs_tools.library.cifti_stuff import (\n",
    "    get_brain_model_axes, get_label_axes, get_subcortical_indices\n",
    ")\n",
    "from mfs_tools.library.file_stuff import (\n",
    "    find_infomap_path, find_wb_command_path,\n",
    "    read_pajek_file, write_pajek_file, compare_pajek_data,\n",
    "    load_infomap_clu_file\n",
    ")\n",
    "\n",
    "\n",
    "save_to = Path(\"/mnt/cache/pfm_python\")\n",
    "ml_base_path = Path(\"/mnt/cache/pfm_matlab\")\n",
    "python_cifti_path = (\n",
    "    save_to /\n",
    "    \"sub-ME01_task-rest_concatenated_demeaned_regressed_and_smoothed-2.55_32k_fsLR.dtseries.nii\"\n",
    ")\n",
    "matlab_cifti_path = (\n",
    "    ml_base_path /\n",
    "    \"sub-ME01_task-rest_concatenated_demeaned_regressed_and_smoothed-2.55_32k_fsLR.dtseries.nii\"\n",
    ")\n",
    "surface_files = {\n",
    "    'lh': Path(\n",
    "        \"/mnt/brunodata/open_data/ds005118/derivatives/sub-ME01/fs_LR/fsaverage_LR32k\"\n",
    "        \"/ME01.L.midthickness.32k_fs_LR.surf.gii\"\n",
    "    ),\n",
    "    'rh': Path(\n",
    "        \"/mnt/brunodata/open_data/ds005118/derivatives/sub-ME01/fs_LR/fsaverage_LR32k\"\n",
    "        \"/ME01.R.midthickness.32k_fs_LR.surf.gii\"\n",
    "    ),\n",
    "}\n",
    "python_distance_matrix_path = save_to / \"dist_complete.npy\"\n",
    "matlab_distance_matrix_path = ml_base_path / \"DistanceMatrix.mat\"\n",
    "\n",
    "wb_command_path = find_wb_command_path()\n",
    "\n",
    "# The infomap executable was installed via pip in our virtual environment.\n",
    "path_to_infomap = find_infomap_path(\"/home/mike/.virtualenvs/fmri/bin/infomap\")\n",
    "work_dir = Path(\"/mnt/cache/pfm_python/infomap_work\")\n",
    "work_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for p in (\n",
    "    save_to, ml_base_path, python_cifti_path, matlab_cifti_path,\n",
    "    surface_files['lh'], surface_files['rh'],\n",
    "    python_distance_matrix_path, matlab_distance_matrix_path,\n",
    "    wb_command_path, path_to_infomap, work_dir,\n",
    "):\n",
    "    if not p.exists():\n",
    "        print(f\"File '{str(p)}' does not exist.\")\n",
    "\n",
    "#  5.5 to 5.7GB RAM"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T02:04:21.559692Z",
     "start_time": "2025-03-13T02:00:21.347467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load input data\n",
    "\n",
    "# For initial debugging, use the matlab data so any minor differences\n",
    "# are due to this code, not prior variability\n",
    "use_matlab = False\n",
    "\n",
    "if use_matlab:\n",
    "    smoothed_cifti_img = nib.Cifti2Image.from_filename(matlab_cifti_path)\n",
    "    ml_distance_dict = h5py.File(matlab_distance_matrix_path, 'r')\n",
    "    distance_matrix = np.array(ml_distance_dict.get('D'), dtype=np.uint8)\n",
    "else:\n",
    "    smoothed_cifti_img = nib.Cifti2Image.from_filename(python_cifti_path)\n",
    "    distance_matrix = np.load(python_distance_matrix_path)\n",
    "\n",
    "# 5.7GB to 14.2GB in 3:35, 7.2GB to 15.8GB in 2:56"
   ],
   "id": "c49f2cf399ff6f86",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T02:18:41.149509Z",
     "start_time": "2025-03-13T02:18:03.693116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "distance_threshold = 10\n",
    "print(f\"The distance matrix is {distance_matrix.shape}-shaped.\")\n",
    "print(f\"It has {np.sum(distance_matrix > 0.0):,} non-zero edges.\")\n",
    "print(f\"It has {np.sum(distance_matrix == 0.0):,} zero edges.\")\n",
    "print(f\"It has {np.sum(distance_matrix <= distance_threshold):,} local edges.\")\n",
    "\n",
    "# These numbers match matlab exactly, as they should."
   ],
   "id": "463e1fe7845fea3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance matrix is (85059, 85059)-shaped.\n",
      "It has 7,234,948,400 non-zero edges.\n",
      "It has 85,081 zero edges.\n",
      "It has 17,574,597 local edges.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T02:18:41.234411Z",
     "start_time": "2025-03-13T02:18:41.208544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set up parameters for infomap\n",
    "graph_densities = sorted(\n",
    "    [0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, ],\n",
    "    reverse=True,\n",
    ")\n",
    "num_reps = 50\n",
    "bad_vertices = list()\n",
    "\n",
    "verbose = True\n",
    "\n",
    "# I doubt there's any overlap between the randomization between matlab\n",
    "# and python/numpy/scipy, but Lynch set his seed at 44 and I'll do the\n",
    "# same here.\n",
    "np.random.seed(44)\n"
   ],
   "id": "4b806a0a6e488443",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T02:18:42.009801Z",
     "start_time": "2025-03-13T02:18:41.270856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensure we have more than zero valid structures to work with\n",
    "# I don't know why, but Lynch's code only includes the 10 regions\n",
    "# with distinct LEFT or RIGHT, but this excludes BRAIN_STEM.\n",
    "# I'll exclude it here, too, so code matches, but maybe we can\n",
    "# revisit if we have brainstem-specific hypotheses.\n",
    "# Lynch also put ACCUMBENS in his code twice, one of them\n",
    "# probably replacing 'DIENCEPHALON_VENTRAL', so only\n",
    "# 18 regions remain out of the original 21. For debugging, we'll try to\n",
    "# match exactly, but in practice, using all regions seems better.\n",
    "anat_axis = get_brain_model_axes(smoothed_cifti_img)\n",
    "# The 'anat_axis' already has 85,059 loci,\n",
    "# just like matlab's BrainStructure and BrainStructureLabel,\n",
    "# so we don't need to do anything else with it here.\n",
    "structures = np.unique([\n",
    "    str(name) for name in anat_axis.name\n",
    "    if (\"BRAIN_STEM\" not in name) & ('DIENCEPHALON' not in name)\n",
    "])\n",
    "# There are 20 structures in 'structures'\n",
    "\n",
    "# We need to get indices into each region, so gather all potentials\n",
    "# and cross reference with what we have in our data\n",
    "potential_structures = np.unique([str(name) for name in anat_axis.name])\n",
    "print(f\"Found {len(potential_structures)} potential structures, \"\n",
    "      f\"But we only want {len(structures)}.\")\n",
    "structure_mask = [s in structures for s in potential_structures]\n",
    "structure_indices = np.where(structure_mask)[0]\n",
    "good_structures = potential_structures[structure_indices]\n",
    "print(f\"Indexing leaves us with {len(structure_indices)} structures\")\n",
    "\n",
    "# Now go through each locus to determine if it's in our list of structures.\n",
    "locus_mask = [str(s) in good_structures for s in anat_axis.name]\n",
    "locus_indices = np.where(locus_mask)[0]\n",
    "print(f\"Filtering structures leaves {len(locus_indices)} loci\")\n",
    "\n",
    "# Further, remove any pre-designated bad vertices\n",
    "locus_indices = [li for li in locus_indices if li not in bad_vertices]\n",
    "print(f\"Removing bad verts leaves {len(locus_indices)} loci\")\n",
    "\n",
    "if verbose:\n",
    "    print(f\"Using {len(good_structures)} structures: \")\n",
    "    for i, s in enumerate(good_structures):\n",
    "        print(f\"{i + 1:>2}. {str(s)}\")\n"
   ],
   "id": "e3f25b72272f9993",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 potential structures, But we only want 18.\n",
      "Indexing leaves us with 18 structures\n",
      "Filtering structures leaves 81407 loci\n",
      "Removing bad verts leaves 81407 loci\n",
      "Using 18 structures: \n",
      " 1. CIFTI_STRUCTURE_ACCUMBENS_LEFT\n",
      " 2. CIFTI_STRUCTURE_ACCUMBENS_RIGHT\n",
      " 3. CIFTI_STRUCTURE_AMYGDALA_LEFT\n",
      " 4. CIFTI_STRUCTURE_AMYGDALA_RIGHT\n",
      " 5. CIFTI_STRUCTURE_CAUDATE_LEFT\n",
      " 6. CIFTI_STRUCTURE_CAUDATE_RIGHT\n",
      " 7. CIFTI_STRUCTURE_CEREBELLUM_LEFT\n",
      " 8. CIFTI_STRUCTURE_CEREBELLUM_RIGHT\n",
      " 9. CIFTI_STRUCTURE_CORTEX_LEFT\n",
      "10. CIFTI_STRUCTURE_CORTEX_RIGHT\n",
      "11. CIFTI_STRUCTURE_HIPPOCAMPUS_LEFT\n",
      "12. CIFTI_STRUCTURE_HIPPOCAMPUS_RIGHT\n",
      "13. CIFTI_STRUCTURE_PALLIDUM_LEFT\n",
      "14. CIFTI_STRUCTURE_PALLIDUM_RIGHT\n",
      "15. CIFTI_STRUCTURE_PUTAMEN_LEFT\n",
      "16. CIFTI_STRUCTURE_PUTAMEN_RIGHT\n",
      "17. CIFTI_STRUCTURE_THALAMUS_LEFT\n",
      "18. CIFTI_STRUCTURE_THALAMUS_RIGHT\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T02:27:02.701975Z",
     "start_time": "2025-03-13T02:27:02.532325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mfs_tools import red_on, green_on, color_off\n",
    "excluded_regions = [\"BRAIN_STEM\", ]\n",
    "all_structures, all_counts = np.unique(\n",
    "    [str(name) for name in anat_axis.name], return_counts=True\n",
    ")\n",
    "excluded_structures = list()\n",
    "structures = list()\n",
    "for i, structure in enumerate(all_structures):\n",
    "    locus_str = \"vertices\" if \"CORTEX\" in structure else \"voxels\"\n",
    "    if verbose:\n",
    "        print(f\"  {structure: <42}  \", end=\"\")\n",
    "    for region in excluded_regions:\n",
    "        if (    (region in structure) or\n",
    "                (f\"{region}_LEFT\" in structure) or\n",
    "                (f\"{region}_RIGHT\" in structure)\n",
    "        ):\n",
    "            excluded_structures.append(structure)\n",
    "            if verbose:\n",
    "                print(f\"{red_on}-{color_off}  ({all_counts[i]:,} {locus_str})\")\n",
    "        else:\n",
    "            structures.append(structure)\n",
    "            if verbose:\n",
    "                print(f\"{green_on}+{color_off}  ({all_counts[i]:,} {locus_str})\")\n",
    "if verbose:\n",
    "    print(f\"  found {len(all_structures)} structures, \"\n",
    "          f\"excluded {len(excluded_structures)} of them,\"\n",
    "          f\"and kept {len(structures)} of them.\")\n"
   ],
   "id": "e72c160dab995b54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CIFTI_STRUCTURE_ACCUMBENS_LEFT              \u001B[1;32m+\u001B[0m  (47 voxels)\n",
      "  CIFTI_STRUCTURE_ACCUMBENS_RIGHT             \u001B[1;32m+\u001B[0m  (43 voxels)\n",
      "  CIFTI_STRUCTURE_AMYGDALA_LEFT               \u001B[1;32m+\u001B[0m  (183 voxels)\n",
      "  CIFTI_STRUCTURE_AMYGDALA_RIGHT              \u001B[1;32m+\u001B[0m  (232 voxels)\n",
      "  CIFTI_STRUCTURE_BRAIN_STEM                  \u001B[0;31m-\u001B[0m  (2,634 voxels)\n",
      "  CIFTI_STRUCTURE_CAUDATE_LEFT                \u001B[1;32m+\u001B[0m  (428 voxels)\n",
      "  CIFTI_STRUCTURE_CAUDATE_RIGHT               \u001B[1;32m+\u001B[0m  (426 voxels)\n",
      "  CIFTI_STRUCTURE_CEREBELLUM_LEFT             \u001B[1;32m+\u001B[0m  (7,846 voxels)\n",
      "  CIFTI_STRUCTURE_CEREBELLUM_RIGHT            \u001B[1;32m+\u001B[0m  (8,113 voxels)\n",
      "  CIFTI_STRUCTURE_CORTEX_LEFT                 \u001B[1;32m+\u001B[0m  (29,696 vertices)\n",
      "  CIFTI_STRUCTURE_CORTEX_RIGHT                \u001B[1;32m+\u001B[0m  (29,716 vertices)\n",
      "  CIFTI_STRUCTURE_DIENCEPHALON_VENTRAL_LEFT   \u001B[1;32m+\u001B[0m  (489 voxels)\n",
      "  CIFTI_STRUCTURE_DIENCEPHALON_VENTRAL_RIGHT  \u001B[1;32m+\u001B[0m  (529 voxels)\n",
      "  CIFTI_STRUCTURE_HIPPOCAMPUS_LEFT            \u001B[1;32m+\u001B[0m  (479 voxels)\n",
      "  CIFTI_STRUCTURE_HIPPOCAMPUS_RIGHT           \u001B[1;32m+\u001B[0m  (467 voxels)\n",
      "  CIFTI_STRUCTURE_PALLIDUM_LEFT               \u001B[1;32m+\u001B[0m  (196 voxels)\n",
      "  CIFTI_STRUCTURE_PALLIDUM_RIGHT              \u001B[1;32m+\u001B[0m  (207 voxels)\n",
      "  CIFTI_STRUCTURE_PUTAMEN_LEFT                \u001B[1;32m+\u001B[0m  (628 voxels)\n",
      "  CIFTI_STRUCTURE_PUTAMEN_RIGHT               \u001B[1;32m+\u001B[0m  (656 voxels)\n",
      "  CIFTI_STRUCTURE_THALAMUS_LEFT               \u001B[1;32m+\u001B[0m  (1,072 voxels)\n",
      "  CIFTI_STRUCTURE_THALAMUS_RIGHT              \u001B[1;32m+\u001B[0m  (972 voxels)\n",
      "  found 21 structures, excluded 1 of them,and kept 20 of them.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T19:45:01.774690Z",
     "start_time": "2025-02-15T19:44:35.678400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Trim the distance matrix to match our filtered vertices.\n",
    "# While we're at it, set subcort-subcort distances to zero.\n",
    "print(f\"Original distance matrix is shaped {distance_matrix.shape}\")\n",
    "subcort_indices = get_subcortical_indices(smoothed_cifti_img)\n",
    "distance_matrix[np.ix_(subcort_indices, subcort_indices)] = 0.0\n",
    "print(f\"D1 is shaped {distance_matrix.shape}\")\n",
    "print(f\"D1 has {np.sum(distance_matrix > 0.0):,} non-zero edges.\")\n",
    "print(f\"D1 has {np.sum(distance_matrix == 0.0):,} zero edges.\")\n",
    "print(f\"D1 has {np.sum(distance_matrix <= distance_threshold):,} local edges.\")\n",
    "\n",
    "# These numbers, too, match matlab exactly (but only after using the np.ix_ function)"
   ],
   "id": "d3a416d8e23a8be4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original distance matrix is shaped (85059, 85059)\n",
      "D1 is shaped (85059, 85059)\n",
      "D1 has 6,577,205,438 non-zero edges.\n",
      "D1 has 657,828,043 zero edges.\n",
      "D1 has 665,815,249 local edges.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T19:45:49.039656Z",
     "start_time": "2025-02-15T19:45:01.802373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "distance_matrix = distance_matrix[locus_indices, :][:, locus_indices]\n",
    "print(f\"D2 is shaped {distance_matrix.shape}\")\n",
    "print(f\"D2 has {np.sum(distance_matrix > 0.0):,} non-zero edges.\")\n",
    "print(f\"D2 has {np.sum(distance_matrix == 0.0):,} zero edges.\")\n",
    "print(f\"D2 has {np.sum(distance_matrix <= distance_threshold):,} local edges.\")\n",
    "\n",
    "# 14.2GB to 13.7GB in 1:41\n",
    "# These counts match matlab exactly"
   ],
   "id": "b976778d157d3d8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D2 is shaped (81407, 81407)\n",
      "D2 has 6,143,260,190 non-zero edges.\n",
      "D2 has 483,839,459 zero edges.\n",
      "D2 has 491,759,083 local edges.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T20:05:15.412796Z",
     "start_time": "2025-01-14T20:05:07.427483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"  I don't think we need this; from externally correlating connectivity\n",
    "\n",
    "# This is a pain in the ass. We could theoretically just create a correlation\n",
    "# matrix with numpy, but it runs python (not the VM) out of memory, even on a\n",
    "# VM with 200GB RAM. So we need to be smarter with memory consumption. A quick\n",
    "# workaround is to just let Workbench do the correlation for us.\n",
    "# To do that, we need to prep and save our BOLD data to disk,\n",
    "# then do the correlation, then read it back in.\n",
    "final_bold_anat_axis = get_brain_model_axes(smoothed_cifti_img, verbose=True)[locus_indices]\n",
    "final_bold_time_axis = get_series_axes(smoothed_cifti_img)\n",
    "final_header = nib.cifti2.Cifti2Header.from_axes((\n",
    "    final_bold_time_axis, final_bold_anat_axis\n",
    "))\n",
    "final_dtseries_img = nib.Cifti2Image(\n",
    "    smoothed_cifti_img.get_fdata()[:, locus_indices],\n",
    "    final_header\n",
    ")\n",
    "final_bold_file = (\n",
    "    save_to /\n",
    "    \"sub-ME01_task-rest_concatenated_demeaned_regressed_smoothed-2.55_and_trimmed_32k_fsLR.dtseries.nii\"\n",
    ")\n",
    "dconn_file = (\n",
    "    save_to /\n",
    "    \"sub-ME01_task-rest_concatenated_demeaned_regressed_smoothed-2.55_and_trimmed_32k_fsLR.dconn.nii\"\n",
    ")\n",
    "final_dtseries_img.to_filename(final_bold_file)\n",
    "\"\"\""
   ],
   "id": "598b7e507c928fa5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  discovered axis 0: <class 'nibabel.cifti2.cifti2_axes.SeriesAxis'>\n",
      "  discovered axis 1: <class 'nibabel.cifti2.cifti2_axes.BrainModelAxis'>\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T19:48:40.343186Z",
     "start_time": "2025-02-15T19:47:23.304966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Trim the BOLD data (loaded from matlab's directory earlier) to match\n",
    "# locations in distance matrix.\n",
    "bold_data = smoothed_cifti_img.get_fdata()[:, locus_indices]\n",
    "if (save_to / \"full_connectivity.npy\").exists():\n",
    "    print(f\"Loading full connectivity from {save_to / 'full_connectivity.npy'}\")\n",
    "    full_connectivity = np.load(save_to / \"full_connectivity.npy\")\n",
    "else:\n",
    "    full_connectivity = correlate_bold(bold_data, strip_size=4096, verbose=True)\n",
    "    np.save(save_to / \"full_connectivity.npy\", full_connectivity)\n",
    "\n",
    "# built 13.7GB to 43.8GB in 4:17, loaded 15.2GB to 45.2GB in 1:17"
   ],
   "id": "ae64cd73dd00b3b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading full connectivity from /mnt/cache/pfm_python/full_connectivity.npy\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T19:59:51.556081Z",
     "start_time": "2025-02-15T19:58:35.330370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## On with the actual task at hand, prepping the connectivity for infomap\n",
    "if (save_to / \"final_connectivity.npy\").exists():\n",
    "    print(f\"Loading final connectivity from {save_to / 'final_connectivity.npy'}\")\n",
    "    connectivity = np.load(save_to / \"final_connectivity.npy\")\n",
    "    print(f\"{np.sum(connectivity > 0.0):,} usable edges in the loaded final connectivity.\")\n",
    "else:\n",
    "    connectivity = full_connectivity.copy()\n",
    "    print(f\"Starting with {np.sum(connectivity > 0.0):,} edges.\")\n",
    "\n",
    "    # Remove the diagonal (set to zero)\n",
    "    connectivity[np.diag_indices_from(connectivity)] = 0.0\n",
    "    print(f\"{np.sum(connectivity > 0.0):,} edges remain after removing diagonal\")\n",
    "\n",
    "    # Remove local edges\n",
    "    # (because we set all subcortical-subcortical edges to zero,\n",
    "    #  this also removes them all.)\n",
    "    connectivity[distance_matrix <= distance_threshold] = 0.0\n",
    "    print(f\"{np.sum(connectivity > 0.0):,} edges remain after removing local edges\")\n",
    "\n",
    "    # Remove any NaN values\n",
    "    connectivity[np.isnan(connectivity)] = 0.0\n",
    "    print(f\"{np.sum(connectivity > 0.0):,} edges remain after removing NaNs\")\n",
    "\n",
    "    # Save connectivity for comparison with matlab's filtered connectivity.\n",
    "    np.save(save_to / \"final_connectivity.npy\", connectivity)\n",
    "\n",
    "# ? 43.8GB to 43.8GB in 2:22, loaded 45.3GB to 71.9GB in 1:16\n",
    "# These counts are identical to those from matlab\n",
    "# Expect 3,005,438,468 non-zero edges"
   ],
   "id": "4f460117ab761735",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,005,438,468 usable edges in the loaded final connectivity.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T20:08:01.405808Z",
     "start_time": "2025-02-15T20:00:25.593080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load matlab's final connectivity\n",
    "ml_conn_file = ml_base_path / \"FinalConnectivity.mat\"\n",
    "ml_conn_dict = h5py.File(ml_conn_file, 'r')\n",
    "ml_final_connectivity = np.array(ml_conn_dict.get('m'), dtype=np.float32)\n",
    "\n",
    "# loaded 71.9GB to 99.4GB in 7:35\n"
   ],
   "id": "d21fe7f1de5f84fe",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T20:20:11.336833Z",
     "start_time": "2025-02-15T20:19:16.045644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Comparing the entire matrices could exhaust memory, so we'll just\n",
    "# spot check a few areas.\n",
    "# Some top rows\n",
    "compare_mats(\n",
    "    connectivity[:16384,:],\n",
    "    ml_final_connectivity[:16384,:],\n",
    "    a_name=\"python\", b_name=\"matlab\",\n",
    "    verbose=True\n",
    ")\n",
    "# Some columns in the middle\n",
    "compare_mats(\n",
    "    connectivity[:, 16384:32768],\n",
    "    ml_final_connectivity[:, 16384:32768],\n",
    "    a_name=\"python\", b_name=\"matlab\",\n",
    "    verbose=True\n",
    ")\n",
    "# A block with some subcortical regions\n",
    "compare_mats(\n",
    "    connectivity[49152:73728, 49152:73728],\n",
    "    ml_final_connectivity[49152:73728, 49152:73728],\n",
    "    a_name=\"python\", b_name=\"matlab\",\n",
    "    verbose=True\n",
    ")\n"
   ],
   "id": "fc6ed25e36b49401",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;32m  The matrices 'python' and 'matlab' are equal, with tolerance of 1e-05.\u001B[0m\n",
      "  Mem before 87,618.1MB; Mem after 87,618.6MB; delta 0.5\n",
      "\u001B[1;32m  The matrices 'python' and 'matlab' are equal, with tolerance of 1e-05.\u001B[0m\n",
      "  Mem before 87,618.6MB; Mem after 87,618.6MB; delta 0.0\n",
      "\u001B[1;32m  The matrices 'python' and 'matlab' are equal, with tolerance of 1e-05.\u001B[0m\n",
      "  Mem before 87,618.6MB; Mem after 87,618.6MB; delta 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T01:57:21.192646Z",
     "start_time": "2025-01-17T00:29:46.010153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Next, go through the connectivity matrix, with local edges, diagonals,\n",
    "# and NaNs removed, and sort each column to find\n",
    "# the highest connectivity edges for each locus.\n",
    "# For each column, set the top edges (thresholded by graph density) to True,\n",
    "# leaving everything else False.\n",
    "# This ensures that even weakly connected loci maintain some\n",
    "# connectivity to their hub-like partners.\n",
    "\n",
    "total_edges_kept = 0  # not accurate, some overlap, but useful for comparisons\n",
    "\n",
    "for i_d, d in enumerate(graph_densities):\n",
    "    print(f\"Starting density {d} at {datetime.now()}...\")\n",
    "    log_notes = list()\n",
    "\n",
    "    # Create a mask with all False until we decide what to keep.\n",
    "    hi_conn_mask = np.zeros(connectivity.shape, dtype=bool)\n",
    "    # for each column in the connectivity matrix, find the highest\n",
    "    # correlations and add those edges to the mask for that location's\n",
    "    # column AND row.\n",
    "    for i_n in range(connectivity.shape[1]):\n",
    "        if np.any(connectivity[:, i_n]):\n",
    "            ordered_connectivity = np.flip(np.argsort(connectivity[:, i_n]))\n",
    "            num_to_keep = int(np.ceil(d * len(ordered_connectivity)))\n",
    "            total_edges_kept += num_to_keep\n",
    "            log_notes.append(\n",
    "                f\"Keeping {num_to_keep:,} edges for density {d}, col {i_n}\"\n",
    "            )\n",
    "            # for v in ordered_connectivity[:num_to_keep]:\n",
    "            #     print(f\"Index {v} == {m[v, i_n]:0.3f}\")\n",
    "            hi_conn_mask[ordered_connectivity[:num_to_keep], i_n] = True\n",
    "            hi_conn_mask[i_n, ordered_connectivity[:num_to_keep]] = True\n",
    "\n",
    "    # We built the matrix up symmetrically, so now that it's complete,\n",
    "    # we only need half of it. Delete the lower triangle, then\n",
    "    # find the indices of the masked edges.\n",
    "    hi_conn_mask[np.tril_indices_from(hi_conn_mask)] = False\n",
    "    hi_conn_idx = np.argwhere(hi_conn_mask)\n",
    "    write_pajek_file(\n",
    "        hi_conn_idx, connectivity, save_to / f\"hi_conn_d-{d:0.4f}.net\",\n",
    "        verbose=True\n",
    "    )\n",
    "    with open(save_to / f\"hi_conn_d-{d:0.4f}.log\", 'w') as f:\n",
    "        f.write(\"\\n\".join(log_notes))\n",
    "\n",
    "    print(f\"Finished density {d} at {datetime.now()}...\")\n",
    "\n",
    "# 43.9GB\n",
    "#   for d=0.05: slow to 50, fast to 110, drop to 104, drop to 54, drop to 48 in ~15 min\n",
    "#   for d=0.02: slow to 50, fast to 113, drop to 108, drop fast to 55, drop to 52, drop to 46.5 in ~11 min\n",
    "#   for d=0.01: to 104.8GB, drop fast to 52.6GB"
   ],
   "id": "e2fe031186b9235c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting density 0.05 at 2025-01-16 19:29:46.035625...\n",
      "Wrote 81407 vertices, and 253022347 edges to '/mnt/cache/pfm_python/hi_conn_d-0.0500.net'\n",
      "Finished density 0.05 at 2025-01-16 19:46:03.743309...\n",
      "Starting density 0.02 at 2025-01-16 19:46:03.743576...\n",
      "Wrote 81407 vertices, and 106869594 edges to '/mnt/cache/pfm_python/hi_conn_d-0.0200.net'\n",
      "Finished density 0.02 at 2025-01-16 19:57:39.861257...\n",
      "Starting density 0.01 at 2025-01-16 19:57:39.861451...\n",
      "Wrote 81407 vertices, and 55118427 edges to '/mnt/cache/pfm_python/hi_conn_d-0.0100.net'\n",
      "Finished density 0.01 at 2025-01-16 20:07:38.294529...\n",
      "Starting density 0.005 at 2025-01-16 20:07:38.294647...\n",
      "Wrote 81407 vertices, and 28321685 edges to '/mnt/cache/pfm_python/hi_conn_d-0.0050.net'\n",
      "Finished density 0.005 at 2025-01-16 20:16:15.772485...\n",
      "Starting density 0.002 at 2025-01-16 20:16:15.772603...\n",
      "Wrote 81407 vertices, and 11655995 edges to '/mnt/cache/pfm_python/hi_conn_d-0.0020.net'\n",
      "Finished density 0.002 at 2025-01-16 20:24:21.153913...\n",
      "Starting density 0.001 at 2025-01-16 20:24:21.154183...\n",
      "Wrote 81407 vertices, and 5974445 edges to '/mnt/cache/pfm_python/hi_conn_d-0.0010.net'\n",
      "Finished density 0.001 at 2025-01-16 20:32:35.340220...\n",
      "Starting density 0.0005 at 2025-01-16 20:32:35.340397...\n",
      "Wrote 81407 vertices, and 3038114 edges to '/mnt/cache/pfm_python/hi_conn_d-0.0005.net'\n",
      "Finished density 0.0005 at 2025-01-16 20:41:01.330111...\n",
      "Starting density 0.0002 at 2025-01-16 20:41:01.330242...\n",
      "Wrote 81407 vertices, and 1285725 edges to '/mnt/cache/pfm_python/hi_conn_d-0.0002.net'\n",
      "Finished density 0.0002 at 2025-01-16 20:49:11.232245...\n",
      "Starting density 0.0001 at 2025-01-16 20:49:11.232430...\n",
      "Wrote 81407 vertices, and 690434 edges to '/mnt/cache/pfm_python/hi_conn_d-0.0001.net'\n",
      "Finished density 0.0001 at 2025-01-16 20:57:21.183170...\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T20:25:40.669655Z",
     "start_time": "2025-02-15T20:25:28.715128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The above code block wrote Pajek network definition files for each threshold.\n",
    "# Here, read them.\n",
    "\n",
    "py_net2 = read_pajek_file(save_to / f\"hi_conn_d-0.0002.net\")\n",
    "ml_net2 = read_pajek_file(\n",
    "    ml_base_path / f\"Bipartite_Density0.0002.net\"\n",
    ")\n",
    "py_net1 = read_pajek_file(save_to / f\"hi_conn_d-0.0001.net\")\n",
    "ml_net1 = read_pajek_file(\n",
    "    ml_base_path / f\"Bipartite_Density0.0001.net\"\n",
    ")\n"
   ],
   "id": "e374d06af674019d",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T20:25:41.972339Z",
     "start_time": "2025-02-15T20:25:40.688412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "diff_dict_1 = compare_pajek_data(py_net1, ml_net1)\n",
    "# Python and matlab agreed 100% with identical networks."
   ],
   "id": "a97d46cc1bf8e41e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T20:25:45.665276Z",
     "start_time": "2025-02-15T20:25:43.246248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "diff_dict_2 = compare_pajek_data(py_net2, ml_net2)\n",
    "# Python and matlab disagreed on only 1 of 1,285,725 edges, and the\n",
    "# mismatched edges had identical connectivity."
   ],
   "id": "1230657734e595f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges in A but not B: 1\n",
      "Edges in B but not A: 1\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T02:33:36.620219Z",
     "start_time": "2025-01-18T02:33:36.590172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Memory on henry running 6 infomaps climbed from 12GB after deleting m\n",
    "# gradually higher over 10ish minutes. It eventually exhausted memory and rebooted.\n",
    "# Be careful with memory consumption. I'm tracking it in several places\n",
    "# with valgrind to spec VMs for running this.\n",
    "\n",
    "# Running infomap creates a .clu and a .log file to accompany the .net Pajek file.\n"
   ],
   "id": "72ea41d9029da81d",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T17:20:50.205194Z",
     "start_time": "2025-01-18T17:20:50.148074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "connectivity, full_connectivity = None, None\n",
    "ordered_connectivity = None\n",
    "distance_matrix, bold_data = None, None"
   ],
   "id": "fb725c36f5ab3a7",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T17:21:17.794759Z",
     "start_time": "2025-01-18T17:21:17.366618Z"
    }
   },
   "cell_type": "code",
   "source": "hi_conn_idx, hi_conn_mask = None, None",
   "id": "91334b75c2d3a365",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T22:41:07.282743Z",
     "start_time": "2025-01-18T22:41:07.221948Z"
    }
   },
   "cell_type": "code",
   "source": "smoothed_cifti_img = None\n",
   "id": "1538ed1d65587896",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T22:41:46.699212Z",
     "start_time": "2025-02-15T22:41:46.356059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pre-allocate data for a new Cifti file of Infomap data\n",
    "infomap_data = np.zeros(\n",
    "    (len(anat_axis), len(graph_densities)),\n",
    "    dtype=np.int8\n",
    ")\n",
    "# We need 81407 good locus indices ranging from 0 to 85058;\n",
    "# They're already stored in locus_indices\n",
    "\n",
    "# We previously ran infomap on the matlab data for fair comparisons across\n",
    "# results, so load it from there rather than from our own python data.\n",
    "ml_network_path = Path(\"/mnt/brunodata/open_data/ds005118/derivatives/sub-ME01/pfm_matlab\")\n",
    "\n",
    "# Extract community membership, matched by node_id, and\n",
    "# save it into a single matrix, created just above.\n",
    "for i, density in enumerate(graph_densities):\n",
    "    # For a given density,\n",
    "    # For python-local, clu_filename = f\"hi_conn_d-{density:0.4f}.clu\"\n",
    "    clu_filename = f\"Bipartite_Density{density}.clu\"\n",
    "    infomap_output = load_infomap_clu_file(\n",
    "        ml_network_path / clu_filename, verbose=True\n",
    "    )\n",
    "    infomap_data[locus_indices, i] = infomap_output.sort_values(\n",
    "        ['node_id', ]\n",
    "    )['module'].values\n"
   ],
   "id": "93a7f37fd2a52332",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from '/mnt/brunodata/open_data/ds005118/derivatives/sub-ME01/pfm_matlab/Bipartite_Density0.05.clu'...\n",
      "  found column names as ('node_id', 'module', 'flow')\n",
      "  after 10 header lines, assuming the rest are data\n",
      "  file contained 81,407 nodes.\n",
      "Reading from '/mnt/brunodata/open_data/ds005118/derivatives/sub-ME01/pfm_matlab/Bipartite_Density0.02.clu'...\n",
      "  found column names as ('node_id', 'module', 'flow')\n",
      "  after 10 header lines, assuming the rest are data\n",
      "  file contained 81,407 nodes.\n",
      "Reading from '/mnt/brunodata/open_data/ds005118/derivatives/sub-ME01/pfm_matlab/Bipartite_Density0.01.clu'...\n",
      "  found column names as ('node_id', 'module', 'flow')\n",
      "  after 10 header lines, assuming the rest are data\n",
      "  file contained 81,407 nodes.\n",
      "Reading from '/mnt/brunodata/open_data/ds005118/derivatives/sub-ME01/pfm_matlab/Bipartite_Density0.005.clu'...\n",
      "  found column names as ('node_id', 'module', 'flow')\n",
      "  after 10 header lines, assuming the rest are data\n",
      "  file contained 81,407 nodes.\n",
      "Reading from '/mnt/brunodata/open_data/ds005118/derivatives/sub-ME01/pfm_matlab/Bipartite_Density0.002.clu'...\n",
      "  found column names as ('node_id', 'module', 'flow')\n",
      "  after 10 header lines, assuming the rest are data\n",
      "  file contained 81,407 nodes.\n",
      "Reading from '/mnt/brunodata/open_data/ds005118/derivatives/sub-ME01/pfm_matlab/Bipartite_Density0.001.clu'...\n",
      "  found column names as ('node_id', 'module', 'flow')\n",
      "  after 10 header lines, assuming the rest are data\n",
      "  file contained 81,407 nodes.\n",
      "Reading from '/mnt/brunodata/open_data/ds005118/derivatives/sub-ME01/pfm_matlab/Bipartite_Density0.0005.clu'...\n",
      "  found column names as ('node_id', 'module', 'flow')\n",
      "  after 10 header lines, assuming the rest are data\n",
      "  file contained 81,407 nodes.\n",
      "Reading from '/mnt/brunodata/open_data/ds005118/derivatives/sub-ME01/pfm_matlab/Bipartite_Density0.0002.clu'...\n",
      "  found column names as ('node_id', 'module', 'flow')\n",
      "  after 10 header lines, assuming the rest are data\n",
      "  file contained 81,407 nodes.\n",
      "Reading from '/mnt/brunodata/open_data/ds005118/derivatives/sub-ME01/pfm_matlab/Bipartite_Density0.0001.clu'...\n",
      "  found column names as ('node_id', 'module', 'flow')\n",
      "  after 10 header lines, assuming the rest are data\n",
      "  file contained 81,407 nodes.\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T22:41:48.210320Z",
     "start_time": "2025-02-15T22:41:48.193816Z"
    }
   },
   "cell_type": "code",
   "source": "print(infomap_data[:6, :])",
   "id": "ec9d6c53a29ffd16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 10  1  1  2  2  7  1  3]\n",
      " [ 3  6  2  2  1  1  1  2  5]\n",
      " [ 3 13  2  2  1  1  1  3 10]\n",
      " [ 4  3  1  1  2  2  6  1  3]\n",
      " [ 5  2  2  3  4  4  4  4  1]\n",
      " [ 1  3  1  1  3  2  3  1  4]]\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T22:41:49.819903Z",
     "start_time": "2025-02-15T22:41:49.802636Z"
    }
   },
   "cell_type": "code",
   "source": "infomap_backup_data = infomap_data.copy()",
   "id": "e53132586cafea33",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T23:00:47.693351Z",
     "start_time": "2025-02-15T23:00:47.646585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_edges_removed = 0\n",
    "most_communities = 0\n",
    "density_with_most_communities = 0.0\n",
    "for dens_idx, density in enumerate(graph_densities):\n",
    "    unique_communities = np.unique(infomap_data[:, dens_idx])\n",
    "    print(density, unique_communities)\n",
    "    if len(unique_communities) > most_communities:\n",
    "        most_communities = len(unique_communities)\n",
    "        density_with_most_communities = density\n",
    "    for comm_idx, community_id in enumerate(unique_communities):\n",
    "        if community_id != 0:\n",
    "            community_idx = np.where(infomap_data[:, dens_idx]==community_id)[0]\n",
    "            if len(community_idx) < 10:\n",
    "                print(f\"  Removing density {density}'s community {community_id} with only {len(community_idx)} members.\")\n",
    "                infomap_data[community_idx, dens_idx] = 0\n",
    "                total_edges_removed += len(community_idx)\n",
    "\n",
    "print(f\"Removed {total_edges_removed:,} total edges due to small communities.\")\n",
    "print(f\"The largest set of communities was {most_communities}, from d={density_with_most_communities:0.4f}.\")\n"
   ],
   "id": "4e3f1fcbfc6a11cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 [0 1 2 3 4 5 6 7 8 9]\n",
      "0.02 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "0.01 [0 1 2]\n",
      "0.005 [0 1 2 3]\n",
      "0.002 [0 1 2 3 4 5]\n",
      "0.001 [0 1 2 3 4 5 6]\n",
      "0.0005 [0 1 2 3 4 5 6 7 8]\n",
      "0.0002 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "0.0001 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n",
      "Removed 0 total edges due to small communities.\n",
      "The largest set of communities was 22, from d=0.0001.\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T22:41:53.340437Z",
     "start_time": "2025-02-15T22:41:53.269600Z"
    }
   },
   "cell_type": "code",
   "source": "compare_mats(infomap_data, infomap_backup_data, verbose=True)\n",
   "id": "5c3366652cfb302",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  There are mismatches between 'a' (int8)  and 'b' (int8).\n",
      "  Top left corners, for a small preview:\n",
      "|    4.0000,  10.0000,   1.0000,   1.0000,   2.0000 |    |    4.0000,  10.0000,   1.0000,   1.0000,   2.0000 |\n",
      "|    3.0000,   6.0000,   2.0000,   2.0000,   1.0000 |    |    3.0000,   6.0000,   2.0000,   2.0000,   1.0000 |\n",
      "|    3.0000,  13.0000,   2.0000,   2.0000,   1.0000 | vs |    3.0000,  13.0000,   2.0000,   2.0000,   1.0000 |\n",
      "|    4.0000,   3.0000,   1.0000,   1.0000,   2.0000 |    |    4.0000,   3.0000,   1.0000,   1.0000,   2.0000 |\n",
      "|    5.0000,   2.0000,   2.0000,   3.0000,   4.0000 |    |    5.0000,   2.0000,   2.0000,   3.0000,   4.0000 |\n",
      "\u001B[1;32m  Only 1 in 23921 values differ (32 of 765,495). \u001B[0m\n",
      "\u001B[0;31m  The largest difference is 28.0 == 28.000000000 \u001B[0m\n",
      "  Mem before 88,283.0MB; Mem after 88,283.0MB; delta 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T23:27:30.384019Z",
     "start_time": "2025-02-15T23:27:30.324164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mfs_tools.library.utility_stuff import generate_colormap\n",
    "\n",
    "my_cm = generate_colormap(24)\n"
   ],
   "id": "a8f94bab8ee789ec",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T17:03:08.615697Z",
     "start_time": "2025-02-16T17:03:08.567029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first_label = nib.cifti2.Cifti2Label(0, \"0\", 0.0, 0.0, 0.0, 1.0)\n",
    "rest_of_labels = [\n",
    "    nib.cifti2.Cifti2Label(n + 1, f\"{n + 1}\", *my_cm.colors[n])\n",
    "    for n in range(most_communities)\n",
    "]\n",
    "all_labels = [first_label, ] + rest_of_labels\n",
    "packageable_labels = dict([\n",
    "    (lbl.key, (lbl.label, (lbl.red, lbl.green, lbl.blue, lbl.alpha, )))\n",
    "     for lbl in all_labels\n",
    "])\n"
   ],
   "id": "adfd587c49d340b7",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T17:03:17.717379Z",
     "start_time": "2025-02-16T17:03:17.693154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a_label_axis = nib.cifti2.LabelAxis(\n",
    "    [f\"density {d:0.04f}\" for d in graph_densities],\n",
    "    packageable_labels,\n",
    ")\n"
   ],
   "id": "3d2ef5b29c9c56c",
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T18:02:45.839857Z",
     "start_time": "2025-02-16T18:02:45.293387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# wb_view wants the brain_models along the columns, and the\n",
    "# labels along the rows. So here we transpose our data and\n",
    "# create axes to match.\n",
    "network_label_img = nib.cifti2.Cifti2Image(\n",
    "    infomap_data.T, (a_label_axis, anat_axis, )\n",
    ")\n"
   ],
   "id": "ad5973959dd0f6c3",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T18:02:47.976824Z",
     "start_time": "2025-02-16T18:02:47.717922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save these labels as a Cifti file\n",
    "\n",
    "network_label_img.update_headers()\n",
    "network_label_img.to_filename(\n",
    "    Path(f\"/mnt/cache/pfm_python/\") /\n",
    "         f\"infomap_calculated_network_atlases_over_9_densities.dlabel.nii\"\n",
    ")\n"
   ],
   "id": "1b88aaf7f84bd837",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:44:12.659613Z",
     "start_time": "2025-02-17T17:44:12.485221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_label_axis = get_label_axes(network_label_img)\n",
    "_atlas_data = network_label_img.get_fdata()\n"
   ],
   "id": "74118948c098d904",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:45:26.141869Z",
     "start_time": "2025-02-17T17:45:26.084119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_labels = _atlas_data[2, :]\n",
    "np.unique(_labels, return_counts=True)"
   ],
   "id": "a30117ca03428f91",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2.]), array([ 3652, 42832, 38575]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T17:55:09.307841Z",
     "start_time": "2025-02-17T17:55:09.288220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_mask = (_labels == 1).astype(np.uint8)\n",
    "np.unique(_mask, return_counts=True)"
   ],
   "id": "afde2baa00a04fe7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=uint8), array([42227, 42832]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T22:43:19.468657Z",
     "start_time": "2025-02-17T22:43:19.413839Z"
    }
   },
   "cell_type": "code",
   "source": "_label_axis.name[0]",
   "id": "820c8ff005d4408c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.str_('density 0.0500')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dict([\n",
    "    (lbl.key, (lbl.label, (lbl.red, lbl.green, lbl.blue, lbl.alpha, )))\n",
    "     for lbl in all_labels\n",
    "])"
   ],
   "id": "90ec73f98b6e4a58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T22:46:08.969695Z",
     "start_time": "2025-02-17T22:46:08.934253Z"
    }
   },
   "cell_type": "code",
   "source": "_label_axis.label[2]",
   "id": "22a80b3b4bde627e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ('0', (0.0, 0.0, 0.0, 1.0)),\n",
       " 1: ('1', (0.2, 0.0, 0.0, 1.0)),\n",
       " 2: ('2', (0.2571428571428572, 0.21441197911786147, 0.0, 1.0)),\n",
       " 3: ('3', (0.09717383835030897, 0.31428571428571433, 0.0, 1.0)),\n",
       " 4: ('4', (0.0, 0.3714285714285715, 0.19486330170979507, 1.0)),\n",
       " 5: ('5', (0.0, 0.2650220903897375, 0.42857142857142866, 1.0)),\n",
       " 6: ('6', (0.10464203589203577, 0.0, 0.4857142857142858, 1.0)),\n",
       " 7: ('7', (0.5428571428571429, 0.0, 0.503540368613898, 1.0)),\n",
       " 8: ('8', (0.6000000000000001, 0.12507365448541918, 0.0, 1.0)),\n",
       " 9: ('9', (0.6293585587703238, 0.6571428571428573, 0.0, 1.0)),\n",
       " 10: ('10', (0.07195242489360164, 0.7142857142857144, 0.0, 1.0)),\n",
       " 11: ('11', (0.0, 0.7714285714285716, 0.5655240594136617, 1.0)),\n",
       " 12: ('12', (0.0, 0.33965528046410415, 0.8285714285714287, 1.0)),\n",
       " 13: ('13', (0.3959650941268589, 0.0, 0.8857142857142859, 1.0)),\n",
       " 14: ('14', (0.9428571428571431, 0.0, 0.6780257997169767, 1.0)),\n",
       " 15: ('15', (1.0, 0.4169121816180639, 0.0, 1.0)),\n",
       " 16: ('16', (0.7492634551458082, 1.0, 0.0, 1.0)),\n",
       " 17: ('17', (0.0, 1.0, 0.10772241105651532, 1.0)),\n",
       " 18: ('18', (0.0, 1.0, 0.9647031631761764, 1.0)),\n",
       " 19: ('19', (0.0, 0.201472695957991, 1.0, 1.0)),\n",
       " 20: ('20', (0.6555134551458082, 0.0, 1.0, 1.0)),\n",
       " 21: ('21', (1.0, 0.0, 0.5106621816180639, 1.0)),\n",
       " 22: ('22', (1.0, 0.812684136213548, 0.5, 1.0))}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T22:47:25.407206Z",
     "start_time": "2025-02-17T22:47:25.388903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "one_comm_label_axis = nib.cifti2.LabelAxis(\n",
    "    _label_axis.name[2:3],\n",
    "    [_label_axis.label[2], ],\n",
    ")"
   ],
   "id": "951e35593fbe3b29",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T00:49:12.813201Z",
     "start_time": "2025-02-18T00:49:12.767961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_mask.reshape(1, -1).shape\n",
    "np.unique(_mask, return_counts=True)"
   ],
   "id": "7b699641786ccbc5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=uint8), array([42227, 42832]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T01:52:04.399391Z",
     "start_time": "2025-02-18T01:52:03.391230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "\n",
    "wb_command = find_wb_command_path()\n",
    "d_i, d = 2, _label_axis.name[2]\n",
    "c = 2\n",
    "min_area = 50\n",
    "filename = f\"tmp_{d.replace(' ', '-')}_c-{c:02d}_mask.dscalar.nii\"\n",
    "\n",
    "_mask_data = (_labels == c).astype(np.uint8).reshape(1, -1)\n",
    "\n",
    "community_scalar_axis = nib.cifti2.ScalarAxis(\n",
    "    [f\"community {c}\", ]\n",
    ")\n",
    "# community_label_axis = nib.cifti2.LabelAxis(\n",
    "#     [d, ], [_label_axis.label[d_i], ]\n",
    "# )\n",
    "community_img = nib.cifti2.Cifti2Image(\n",
    "    _mask.reshape(1, -1), (community_scalar_axis, anat_axis)\n",
    ")\n",
    "community_img.to_filename(Path(work_dir) / filename)\n"
   ],
   "id": "72bbcf2f9eb7f393",
   "outputs": [],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T01:52:10.395570Z",
     "start_time": "2025-02-18T01:52:10.043633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "proc = subprocess.run([\n",
    "    wb_command,\n",
    "    \"-cifti-find-clusters\",\n",
    "    str(Path(work_dir) / filename),\n",
    "    \"0\", str(min_area), \"0\", str(min_area), \"COLUMN\",\n",
    "    str(Path(work_dir) / filename.replace(\"_mask\", \"_cmask\")),\n",
    "    \"-left-surface\", surface_files['lh'],\n",
    "    \"-right-surface\", surface_files['rh'],\n",
    "    \"-merged-volume\"\n",
    "])\n"
   ],
   "id": "bf4da145f07715ca",
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T01:52:28.117584Z",
     "start_time": "2025-02-18T01:52:26.940567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_mask = nib.cifti2.Cifti2Image.from_filename(\n",
    "    Path(work_dir) / filename.replace(\"_mask\", \"_cmask\")\n",
    ").get_fdata()\n",
    "print(np.unique(_mask_data, return_counts=True))\n",
    "print(np.unique(new_mask, return_counts=True))\n",
    "# So there were 42,227 zeros in the binary mask, and now\n",
    "# there are 42,342, indicating 115 voxels/vertices were in too-small islands.\n",
    "# So let's investigate those.\n",
    "_tiny_islets = ((new_mask == 0) & (_mask_data > 0)).astype(np.uint8)\n",
    "islet_scalar_axis = nib.cifti2.ScalarAxis(\n",
    "    [f\"itty bitties\", ]\n",
    ")\n",
    "islet_img = nib.cifti2.Cifti2Image(\n",
    "    _tiny_islets, (islet_scalar_axis, anat_axis)\n",
    ")\n",
    "islet_img.to_filename(Path(work_dir) / \"islets.2.dscalar.nii\")\n"
   ],
   "id": "ea59473d35ae3d29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1], dtype=uint8), array([46484, 38575]))\n",
      "(array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "       13., 14., 15., 16., 17., 18., 19., 20., 21.]), array([42342,  8759,  7094,    20,    27,    37,    29,  7615,  6440,\n",
      "          23,  9172,     9,   386,  2741,    32,    44,   128,    29,\n",
      "           7,    57,    53,    15]))\n"
     ]
    }
   ],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T01:48:44.043975Z",
     "start_time": "2025-02-18T01:48:44.013898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filtered_atlas_data = np.zeros(_atlas_data.shape)\n",
    "print(filtered_atlas_data.shape)\n"
   ],
   "id": "723da720fda3a7b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 85059)\n"
     ]
    }
   ],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T01:52:37.471787Z",
     "start_time": "2025-02-18T01:52:37.425150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(np.unique(_atlas_data[d_i, :], return_counts=True))\n",
    "filtered_atlas_data[d_i, new_mask.astype(np.bool).ravel()] = c\n",
    "# filtered_atlas_data = _atlas_data[d_i, :].reshape(1, -1) * new_mask.astype(np.bool).astype(np.uint8)\n",
    "print(np.unique(filtered_atlas_data, return_counts=True))\n"
   ],
   "id": "ae7d56085b627ae9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1., 2.]), array([ 3652, 42832, 38575]))\n",
      "(array([0., 2.]), array([722814,  42717]))\n"
     ]
    }
   ],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T01:41:51.508756Z",
     "start_time": "2025-02-18T01:41:51.487519Z"
    }
   },
   "cell_type": "code",
   "source": "_atlas_data[d_i, :].shape",
   "id": "6bfe18e4b0684304",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85059,)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T23:40:39.647331Z",
     "start_time": "2025-02-17T23:40:39.605385Z"
    }
   },
   "cell_type": "code",
   "source": "compare_mats(_mask.reshape(1, -1), new_mask, verbose=True)\n",
   "id": "f7474a8e5b824e2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  There are mismatches between 'a' (uint8)  and 'b' (float64).\n",
      "  Top left corners, for a small preview:\n",
      "|    1.0000,   0.0000,   0.0000,   1.0000,   0.0000 |    |    1.0000,   0.0000,   0.0000,   2.0000,   0.0000 |\n",
      "\u001B[0;31m  0 of 1 values differ. The mean difference, where there are differences,  is nan.\u001B[0m\n",
      "\u001B[1;32m  The largest difference is nan == nan \u001B[0m\n",
      "  Mem before 88,314.3MB; Mem after 88,314.3MB; delta 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T23:37:55.685514Z",
     "start_time": "2025-02-17T23:37:55.618652Z"
    }
   },
   "cell_type": "code",
   "source": "np.sum(np.isnan(_mask.reshape(1, -1)))",
   "id": "42d14ac806d935cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T23:38:22.958250Z",
     "start_time": "2025-02-17T23:38:22.929228Z"
    }
   },
   "cell_type": "code",
   "source": "np.sum(np.isnan(new_mask))",
   "id": "beec280e6134ac2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T23:38:43.672510Z",
     "start_time": "2025-02-17T23:38:43.643219Z"
    }
   },
   "cell_type": "code",
   "source": "_mask.reshape(1, -1).shape, new_mask.shape",
   "id": "23b5b7384aa7545a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 85059), (1, 85059))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T23:41:17.100231Z",
     "start_time": "2025-02-17T23:41:17.069376Z"
    }
   },
   "cell_type": "code",
   "source": "np.allclose(_mask.reshape(1, -1), new_mask)",
   "id": "daa0baa5bf8c91e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T23:41:54.295032Z",
     "start_time": "2025-02-17T23:41:54.263752Z"
    }
   },
   "cell_type": "code",
   "source": "np.unique(_mask.reshape(1, -1), return_counts=True)\n",
   "id": "7f308a58feed341c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=uint8), array([42227, 42832]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T23:42:09.737938Z",
     "start_time": "2025-02-17T23:42:09.704286Z"
    }
   },
   "cell_type": "code",
   "source": "np.unique(new_mask, return_counts=True)\n",
   "id": "15ef2378e1a6fa00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "        13., 14., 15., 16., 17., 18., 19., 20., 21.]),\n",
       " array([42342,  8759,  7094,    20,    27,    37,    29,  7615,  6440,\n",
       "           23,  9172,     9,   386,  2741,    32,    44,   128,    29,\n",
       "            7,    57,    53,    15]))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T02:54:34.275487Z",
     "start_time": "2025-02-18T02:52:42.875986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mfs_tools.library.clustering_stuff import spatial_filter\n",
    "\n",
    "new_img = spatial_filter(\n",
    "    network_label_img, surface_files['lh'], surface_files['rh'],\n",
    "    work_path=work_dir, verbose=True\n",
    ")\n"
   ],
   "id": "845d91f18a6c4cae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing small islets from 'density 0.0500' communities.\n",
      "    saving 19,306 of 19,544 members of '1'\n",
      "    saving 16,646 of 16,885 members of '2'\n",
      "    saving 12,701 of 12,819 members of '3'\n",
      "    saving 14,932 of 15,116 members of '4'\n",
      "    saving 10,261 of 10,371 members of '5'\n",
      "    saving 3,764 of 4,091 members of '6'\n",
      "    saving 2,361 of 2,425 members of '7'\n",
      "    saving 0 of 130 members of '8'\n",
      "    saving 0 of 12 members of '9'\n",
      "Before:\n",
      "(array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]), array([ 3666, 19544, 16885, 12819, 15116, 10371,  4091,  2425,   130,\n",
      "          12]))\n",
      "After:\n",
      "(array([0., 1., 2., 3., 4., 5., 6., 7.]), array([ 5088, 19306, 16646, 12701, 14932, 10261,  3764,  2361]))\n",
      "Removing small islets from 'density 0.0200' communities.\n",
      "    saving 11,943 of 12,157 members of '1'\n",
      "    saving 10,115 of 10,219 members of '2'\n",
      "    saving 9,244 of 9,425 members of '3'\n",
      "    saving 8,244 of 8,393 members of '4'\n",
      "    saving 7,151 of 7,321 members of '5'\n",
      "    saving 6,551 of 6,850 members of '6'\n",
      "    saving 5,105 of 5,360 members of '7'\n",
      "    saving 5,408 of 5,633 members of '8'\n",
      "    saving 3,991 of 4,134 members of '9'\n",
      "    saving 3,968 of 4,121 members of '10'\n",
      "    saving 2,572 of 2,830 members of '11'\n",
      "    saving 2,446 of 2,515 members of '12'\n",
      "    saving 2,346 of 2,431 members of '13'\n",
      "Before:\n",
      "(array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "       13.]), array([ 3670, 12157, 10219,  9425,  8393,  7321,  6850,  5360,  5633,\n",
      "        4134,  4121,  2830,  2515,  2431]))\n",
      "After:\n",
      "(array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "       13.]), array([ 5975, 11943, 10115,  9244,  8244,  7151,  6551,  5105,  5408,\n",
      "        3991,  3968,  2572,  2446,  2346]))\n",
      "Removing small islets from 'density 0.0100' communities.\n",
      "    saving 42,717 of 42,832 members of '1'\n",
      "    saving 38,460 of 38,575 members of '2'\n",
      "Before:\n",
      "(array([0., 1., 2.]), array([ 3652, 42832, 38575]))\n",
      "After:\n",
      "(array([0., 1., 2.]), array([ 3882, 42717, 38460]))\n",
      "Removing small islets from 'density 0.0050' communities.\n",
      "    saving 43,988 of 44,136 members of '1'\n",
      "    saving 26,374 of 26,472 members of '2'\n",
      "    saving 10,597 of 10,799 members of '3'\n",
      "Before:\n",
      "(array([0., 1., 2., 3.]), array([ 3652, 44136, 26472, 10799]))\n",
      "After:\n",
      "(array([0., 1., 2., 3.]), array([ 4100, 43988, 26374, 10597]))\n",
      "Removing small islets from 'density 0.0020' communities.\n",
      "    saving 29,111 of 29,250 members of '1'\n",
      "    saving 19,537 of 19,779 members of '2'\n",
      "    saving 13,406 of 13,655 members of '3'\n",
      "    saving 9,617 of 9,782 members of '4'\n",
      "    saving 8,756 of 8,941 members of '5'\n",
      "Before:\n",
      "(array([0., 1., 2., 3., 4., 5.]), array([ 3652, 29250, 19779, 13655,  9782,  8941]))\n",
      "After:\n",
      "(array([0., 1., 2., 3., 4., 5.]), array([ 4632, 29111, 19537, 13406,  9617,  8756]))\n",
      "Removing small islets from 'density 0.0010' communities.\n",
      "    saving 28,631 of 28,819 members of '1'\n",
      "    saving 16,369 of 16,596 members of '2'\n",
      "    saving 12,376 of 12,706 members of '3'\n",
      "    saving 9,901 of 10,038 members of '4'\n",
      "    saving 8,697 of 8,909 members of '5'\n",
      "    saving 4,061 of 4,339 members of '6'\n",
      "Before:\n",
      "(array([0., 1., 2., 3., 4., 5., 6.]), array([ 3652, 28819, 16596, 12706, 10038,  8909,  4339]))\n",
      "After:\n",
      "(array([0., 1., 2., 3., 4., 5., 6.]), array([ 5024, 28631, 16369, 12376,  9901,  8697,  4061]))\n",
      "Removing small islets from 'density 0.0005' communities.\n",
      "    saving 30,197 of 30,363 members of '1'\n",
      "    saving 11,413 of 11,707 members of '2'\n",
      "    saving 8,874 of 9,145 members of '3'\n",
      "    saving 8,823 of 9,034 members of '4'\n",
      "    saving 9,034 of 9,260 members of '5'\n",
      "    saving 5,122 of 5,315 members of '6'\n",
      "    saving 4,144 of 4,329 members of '7'\n",
      "    saving 2,052 of 2,254 members of '8'\n",
      "Before:\n",
      "(array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), array([ 3652, 30363, 11707,  9145,  9034,  9260,  5315,  4329,  2254]))\n",
      "After:\n",
      "(array([0., 1., 2., 3., 4., 5., 6., 7., 8.]), array([ 5400, 30197, 11413,  8874,  8823,  9034,  5122,  4144,  2052]))\n",
      "Removing small islets from 'density 0.0002' communities.\n",
      "    saving 16,983 of 17,218 members of '1'\n",
      "    saving 14,019 of 14,354 members of '2'\n",
      "    saving 9,720 of 9,872 members of '3'\n",
      "    saving 8,728 of 8,932 members of '4'\n",
      "    saving 9,151 of 9,399 members of '5'\n",
      "    saving 7,053 of 7,187 members of '6'\n",
      "    saving 3,964 of 4,223 members of '7'\n",
      "    saving 2,452 of 2,676 members of '8'\n",
      "    saving 2,091 of 2,190 members of '9'\n",
      "    saving 1,629 of 1,761 members of '10'\n",
      "    saving 1,647 of 1,766 members of '11'\n",
      "    saving 1,037 of 1,237 members of '12'\n",
      "    saving 567 of 592 members of '13'\n",
      "Before:\n",
      "(array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "       13.]), array([ 3652, 17218, 14354,  9872,  8932,  9399,  7187,  4223,  2676,\n",
      "        2190,  1761,  1766,  1237,   592]))\n",
      "After:\n",
      "(array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "       13.]), array([ 6018, 16983, 14019,  9720,  8728,  9151,  7053,  3964,  2452,\n",
      "        2091,  1629,  1647,  1037,   567]))\n",
      "Removing small islets from 'density 0.0001' communities.\n",
      "    saving 8,939 of 9,173 members of '1'\n",
      "    saving 8,905 of 9,118 members of '2'\n",
      "    saving 8,455 of 8,668 members of '3'\n",
      "    saving 6,387 of 6,575 members of '4'\n",
      "    saving 5,739 of 5,927 members of '5'\n",
      "    saving 4,899 of 5,253 members of '6'\n",
      "    saving 5,382 of 5,614 members of '7'\n",
      "    saving 5,110 of 5,434 members of '8'\n",
      "    saving 2,803 of 3,056 members of '9'\n",
      "    saving 2,424 of 2,510 members of '10'\n",
      "    saving 2,709 of 2,870 members of '11'\n",
      "    saving 2,153 of 2,173 members of '12'\n",
      "    saving 2,073 of 2,190 members of '13'\n",
      "    saving 1,815 of 1,923 members of '14'\n",
      "    saving 1,711 of 1,836 members of '15'\n",
      "    saving 1,917 of 2,012 members of '16'\n",
      "    saving 1,785 of 1,945 members of '17'\n",
      "    saving 1,717 of 1,966 members of '18'\n",
      "    saving 1,190 of 1,298 members of '19'\n",
      "    saving 1,061 of 1,164 members of '20'\n",
      "    saving 613 of 702 members of '21'\n",
      "Before:\n",
      "(array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "       13., 14., 15., 16., 17., 18., 19., 20., 21.]), array([3652, 9173, 9118, 8668, 6575, 5927, 5253, 5614, 5434, 3056, 2510,\n",
      "       2870, 2173, 2190, 1923, 1836, 2012, 1945, 1966, 1298, 1164,  702]))\n",
      "After:\n",
      "(array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "       13., 14., 15., 16., 17., 18., 19., 20., 21.]), array([7272, 8939, 8905, 8455, 6387, 5739, 4899, 5382, 5110, 2803, 2424,\n",
      "       2709, 2153, 2073, 1815, 1711, 1917, 1785, 1717, 1190, 1061,  613]))\n"
     ]
    }
   ],
   "execution_count": 167
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8a5b18c9b730cefa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
