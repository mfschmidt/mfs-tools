{
 "cells": [
  {
   "cell_type": "code",
   "id": "e4baef34b42e09d0",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.spatial.distance import cdist\n",
    "import nibabel as nib\n",
    "from nibabel.affines import apply_affine\n",
    "\n",
    "from mfs_tools.library.distance_stuff import make_distance_matrix, compare_mats\n",
    "\n",
    "\n",
    "save_to = Path(\"/mnt/cache/pfm_python/\")\n",
    "reference_cifti_path = (\n",
    "    save_to /\n",
    "    \"sub-ME01_task-rest_concatenated_and_demeaned_32k_fsLR.dtseries.nii\"\n",
    ")\n",
    "surface_files = {\n",
    "    'lh': Path(\n",
    "        \"/mnt/brunodata/open_data/ds005118/derivatives/sub-ME01/fs_LR/fsaverage_LR32k\"\n",
    "        \"/ME01.L.midthickness.32k_fs_LR.surf.gii\"\n",
    "    ),\n",
    "    'rh': Path(\n",
    "        \"/mnt/brunodata/open_data/ds005118/derivatives/sub-ME01/fs_LR/fsaverage_LR32k\"\n",
    "        \"/ME01.R.midthickness.32k_fs_LR.surf.gii\"\n",
    "    ),\n",
    "}\n",
    "wb_command_path = \"/usr/local/workbench/2.0.1/bin_linux64/wb_command\"\n",
    "work_dir = None\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# We need to build a complete 85059 x 85059 distance matrix in parts:\n",
    "# A complete fsLR can have up to 32492 vertices per hemisphere, but\n",
    "# Lynch's actual data avoids filling the medial wall.\n",
    "\n",
    "#                   cortex                 subcortex\n",
    "#           left hem       right hem\n",
    "#     ðŸ­½                                                ðŸ­¾\n",
    "#       ðŸ­½    (1)     ðŸ­¾ ðŸ­½    (3)     ðŸ­¾ ðŸ­½    (2)     ðŸ­¾\n",
    "#   lh   29696 x 29696   29696 x 29716   29696 x 25647\n",
    "#       ðŸ­¼            ðŸ­¿ ðŸ­¼            ðŸ­¿ ðŸ­¼            ðŸ­¿\n",
    "#       ðŸ­½    (3)     ðŸ­¾ ðŸ­½    (1)     ðŸ­¾ ðŸ­½    (2)     ðŸ­¾\n",
    "#   rh   29716 x 29696   29716 x 29716   29716 x 25647\n",
    "#       ðŸ­¼            ðŸ­¿ ðŸ­¼            ðŸ­¿ ðŸ­¼            ðŸ­¿\n",
    "#       ðŸ­½    (2)     ðŸ­¾ ðŸ­½    (2)     ðŸ­¾ ðŸ­½    (2)     ðŸ­¾\n",
    "#   sc   25647 x 29696   25647 x 29716   25647 x 25647\n",
    "#       ðŸ­¼            ðŸ­¿ ðŸ­¼            ðŸ­¿ ðŸ­¼            ðŸ­¿\n",
    "#     ðŸ­¼                                                ðŸ­¿\n",
    "\n",
    "# If we built it all at once, it would have 7 billion 32-bit floats,\n",
    "# requiring 28GB just to hold it. Debugging this code on a VM was consuming\n",
    "# about 140GB RAM, but by building distance matrices in pieces, and\n",
    "# converting each to uint8 as its built allowed me to run this on my\n",
    "# workstation with peak memory usage of about 54GB."
   ],
   "id": "9bf5d88ca5497b36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----\n",
    "\n",
    "## Calculate left and right cortical distances\n",
    "\n",
    "----"
   ],
   "id": "d72f9652bcc841c0"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "# (1) Start by either loading pre-built single-hemisphere distance matrices\n",
    "#     or building them.\n",
    "\n",
    "mem_before = psutil.Process(os.getpid()).memory_info().rss\n",
    "\n",
    "distance_matrices = dict()\n",
    "for (hemi) in ('lh', 'rh', ):\n",
    "    mat_file = Path(save_to) / f\"dist_{hemi}.npy\"\n",
    "    if mat_file.exists():\n",
    "        distance_matrices[hemi] = np.load(mat_file)\n",
    "    else:\n",
    "        distance_matrices[hemi] = make_distance_matrix(\n",
    "            reference_cifti_path,\n",
    "            surface_files[hemi],\n",
    "            save_to,\n",
    "            num_procs=12,\n",
    "            wb_command_path=wb_command_path,\n",
    "            work_dir=Path(save_to) / \"tmp\",\n",
    "        )\n",
    "        print(f\"built {distance_matrices[hemi].shape}-shaped distance matrix\")\n",
    "        np.save(mat_file, distance_matrices[hemi])\n",
    "\n",
    "py_lh = distance_matrices[\"lh\"]\n",
    "py_rh = distance_matrices[\"rh\"]\n",
    "\n",
    "mem_after = psutil.Process(os.getpid()).memory_info().rss\n",
    "print(f\"Mem before {mem_before / 1024 / 1024:0,.1f}MB; \"\n",
    "      f\"Mem after {mem_after / 1024 / 1024:0,.1f}MB; \"\n",
    "      f\"delta {(mem_after - mem_before) / 1024 / 1024:0,.1f}\")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Matlab\n",
    "- running with 5 workers, finished in 27:53\n",
    "\n",
    "Python\n",
    "- Running with num_procs == 3 finished in 19:38.5\n",
    "- Running with num_procs == 15 finished in 7:44.9\n",
    "- Running with num_procs == 12 finished in 8:32 & 8:28; 7:44 & 7:42; 7:21 & 7:16\n",
    "- Running with 5 workers, finished in 12:57 and 13:30\n"
   ],
   "id": "ebda1ad3ae5253ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the matrices from matlab\n",
    "\n",
    "# Ensure our lh and rh match the lh and rh from matlab.\n",
    "# Then ensure our combined cortical d matches, too.\n",
    "\n",
    "mem_before = psutil.Process(os.getpid()).memory_info().rss\n",
    "\n",
    "matlab_outdir = Path(\"/mnt/cache/pfm_matlab/\")\n",
    "lh_matlab_file = h5py.File(matlab_outdir / \"lh.mat\", 'r')\n",
    "rh_matlab_file = h5py.File(matlab_outdir / \"rh.mat\", 'r')\n",
    "ml_lh = np.array(lh_matlab_file.get('lh'), dtype=np.uint8)\n",
    "ml_rh = np.array(rh_matlab_file.get('rh'), dtype=np.uint8)\n",
    "print(f\"The lh.mat from matlab contains {ml_lh.shape} {str(ml_lh.dtype)}s.\")\n",
    "print(f\"The rh.mat from matlab contains {ml_rh.shape} {str(ml_rh.dtype)}s.\")\n",
    "\n",
    "mem_after = psutil.Process(os.getpid()).memory_info().rss\n",
    "print(f\"Mem before {mem_before / 1024 / 1024:0,.1f}MB; \"\n",
    "      f\"Mem after {mem_after / 1024 / 1024:0,.1f}MB; \"\n",
    "      f\"delta {(mem_after - mem_before) / 1024 / 1024:0,.1f}\")\n"
   ],
   "id": "d44dbe0ef8b19b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----\n",
    "\n",
    "## Calculate subcortical, and subcortex to left and right cortical distances\n",
    "\n",
    "----"
   ],
   "id": "a055a27c9e43f748"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get gifti coordinates to calculate Euclidean distance between them.\n",
    "\n",
    "mem_before = psutil.Process(os.getpid()).memory_info().rss\n",
    "\n",
    "# Get the anatomical brain axis from the reference Cifti2 image\n",
    "ref_img = nib.cifti2.Cifti2Image.from_filename(reference_cifti_path)\n",
    "brain_ax = ref_img.header.get_axis(1)\n",
    "print(f\"Length of cifti2 brain_axis: {len(brain_ax)}\")\n",
    "\n",
    "# Extract the 3D Cartesian coordinates of all surface vertices\n",
    "lh_surface_img = nib.gifti.gifti.GiftiImage.from_filename(surface_files['lh'])\n",
    "rh_surface_img = nib.gifti.gifti.GiftiImage.from_filename(surface_files['rh'])\n",
    "print(\"Gifti Surface coordinates: \"\n",
    "      f\"[{lh_surface_img.darrays[0].data.shape} + \"\n",
    "      f\"{rh_surface_img.darrays[0].data.shape}]\")\n",
    "\n",
    "# Extract the vertex indices into the mapped BOLD data\n",
    "anat_map = {\n",
    "    'CortexLeft': 'CIFTI_STRUCTURE_CORTEX_LEFT',\n",
    "    'CortexRight': 'CIFTI_STRUCTURE_CORTEX_RIGHT',\n",
    "}\n",
    "lh_surf_anat = lh_surface_img.darrays[0].metadata.get('AnatomicalStructurePrimary', '')\n",
    "lh_surf_idx = brain_ax[brain_ax.name == anat_map[lh_surf_anat]]\n",
    "lh_surf_coords = lh_surface_img.darrays[0].data[lh_surf_idx.vertex, :]\n",
    "print(f\"Just vertices in {str(type(lh_surf_idx))} {lh_surf_anat}: {len(lh_surf_idx)}\")\n",
    "rh_surf_anat = rh_surface_img.darrays[0].metadata.get('AnatomicalStructurePrimary', '')\n",
    "rh_surf_idx = brain_ax[brain_ax.name == anat_map[rh_surf_anat]]\n",
    "rh_surf_coords = rh_surface_img.darrays[0].data[rh_surf_idx.vertex, :]\n",
    "print(f\"Just vertices in {str(type(rh_surf_idx))} {rh_surf_anat}: {len(rh_surf_idx)}\")\n",
    "\n",
    "# Get the subcortical voxels, too, from a volumetric grid rather than vertices.\n",
    "# Note that python's voxel locations are consistently shifted relative to\n",
    "# matlab's. Python's x values are ml+2mm, y=ml+2mm, z=ml-2mm.\n",
    "# Maybe 0-based vs 1-based indexing, then multiplied by the affine?\n",
    "# Maybe it's start of voxel vs end of voxel, not center?\n",
    "# It's all relative, so the subcortex-to-subcortex distances are identical,\n",
    "# and distance differences are only between subcortical and cortical.\n",
    "# I've added a 1 below to ensure these data match Lynch's for now.\n",
    "# I also checked for left-right biases in another notebook to see\n",
    "# whether the Lynch matlab distance matrix or the Schmidt python distance\n",
    "# matrix have more left/right bias. Lynch's is less biased, so I think\n",
    "# adding 1 is the correct approach.\n",
    "ctx_labels = list(anat_map.values())\n",
    "subcortical_coordinates = apply_affine(\n",
    "    brain_ax.affine,\n",
    "    brain_ax.voxel[~np.isin(brain_ax.name, ctx_labels)] + 1,\n",
    ")\n",
    "print(\"Nifti subcortical coordinates: \"\n",
    "      f\" = {subcortical_coordinates.shape}\")\n",
    "print(\"Cifti cortical coordinates: \"\n",
    "      f\" = {lh_surf_coords.shape} & {rh_surf_coords.shape}\")\n",
    "\n",
    "whole_brain_coordinates = np.vstack([\n",
    "    lh_surf_coords, rh_surf_coords, subcortical_coordinates\n",
    "])\n",
    "print(\"Whole brain coordinates: \"\n",
    "      f\" = {whole_brain_coordinates.shape}\")\n",
    "\n",
    "\n",
    "mem_after = psutil.Process(os.getpid()).memory_info().rss\n",
    "print(f\"Mem before {mem_before / 1024 / 1024:0,.1f}MB; \"\n",
    "      f\"Mem after {mem_after / 1024 / 1024:0,.1f}MB; \"\n",
    "      f\"delta {(mem_after - mem_before) / 1024 / 1024:0,.1f}\")\n"
   ],
   "id": "c9a7cf0a7a18fab5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# (2) Now, calculate the Euclidean distances between subcortical voxels\n",
    "#     and everywhere. Doing this in three chunks avoids duplication of\n",
    "#     memory, but takes a little longer (seconds, not minutes).\n",
    "\n",
    "mem_before = psutil.Process(os.getpid()).memory_info().rss\n",
    "\n",
    "sc_to_lh_dist = np.uint8(\n",
    "    np.clip(\n",
    "        cdist(subcortical_coordinates, lh_surf_coords) + 0.5,\n",
    "        0, 255\n",
    "    )\n",
    ")\n",
    "sc_to_rh_dist = np.uint8(\n",
    "    np.clip(\n",
    "        cdist(subcortical_coordinates, rh_surf_coords) + 0.5,\n",
    "        0, 255\n",
    "    )\n",
    ")\n",
    "sc_to_sc_dist = np.uint8(\n",
    "    np.clip(\n",
    "        cdist(subcortical_coordinates, subcortical_coordinates) + 0.5,\n",
    "        0, 255\n",
    "    )\n",
    ")\n",
    "print(f\"Euclidean distance matrices: {sc_to_lh_dist.shape}, {sc_to_rh_dist.shape}, {sc_to_sc_dist.shape}\")\n",
    "\n",
    "mem_after = psutil.Process(os.getpid()).memory_info().rss\n",
    "print(f\"Mem before {mem_before / 1024 / 1024:0,.1f}MB; \"\n",
    "      f\"Mem after {mem_after / 1024 / 1024:0,.1f}MB; \"\n",
    "      f\"delta {(mem_after - mem_before) / 1024 / 1024:0,.1f}\")\n"
   ],
   "id": "3f99fe632c01c35d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This works! but it will generate a giant matrix, using about 146GB of RAM.\n",
    "# I verified that all of the piecing together works on a large VM, so\n",
    "# we can confidently do pieces at a time, then uint8 them and stitch them together.\n",
    "\n",
    "# Running this code on a server with >146GB RAM\n",
    "\"\"\"\n",
    "sc_to_ctx_dist = cdist(subcortical_coordinates, used_surface_coordinates)\n",
    "ctx_to_sc_dist = cdist(used_surface_coordinates, subcortical_coordinates)\n",
    "sc_to_sc_dist = cdist(subcortical_coordinates, subcortical_coordinates)\n",
    "euclid_dist = cdist(\n",
    "    whole_brain_coordinates, whole_brain_coordinates,\n",
    ")\n",
    "\n",
    "tmp = euclid_dist[used_surface_coordinates.shape[0]:, :used_surface_coordinates.shape[0]]\n",
    "print(f\"Compare SC-to-CTX part {sc_to_ctx_dist.shape} to part of the whole {tmp.shape}\")\n",
    "print(\"  full \" + \"match\" if np.allclose(sc_to_ctx_dist, tmp) else \"miss\")\n",
    "print(\"  uint8 \" + \"match\" if np.allclose(np.astype(sc_to_ctx_dist, np.uint8), np.astype(tmp, np.uint8)) else \"miss\")\n",
    "\n",
    "tmp = euclid_dist[used_surface_coordinates.shape[0]:, used_surface_coordinates.shape[0]:]\n",
    "print(f\"Compare SC-to-SC part {sc_to_sc_dist.shape} to part of the whole {tmp.shape}\")\n",
    "print(\"  full \" + \"match\" if np.allclose(sc_to_sc_dist, tmp) else \"miss\")\n",
    "print(\"  uint8 \" + \"match\" if np.allclose(np.astype(sc_to_sc_dist, np.uint8), np.astype(tmp, np.uint8)) else \"miss\")\n",
    "\n",
    "tmp = euclid_dist[:used_surface_coordinates.shape[0], used_surface_coordinates.shape[0]:]\n",
    "print(f\"Compare CTX-to-SC part {ctx_to_sc_dist.shape} to part of the whole {tmp.shape}\")\n",
    "print(\"  full \" + \"match\" if np.allclose(ctx_to_sc_dist, tmp) else \"miss\")\n",
    "print(\"  uint8 \" + \"match\" if np.allclose(np.astype(ctx_to_sc_dist, np.uint8), np.astype(tmp, np.uint8)) else \"miss\")\n",
    "\n",
    "print(f\"Compare CTX-to-SC part {ctx_to_sc_dist.shape} to transposed SC-to-CTX {sc_to_ctx_dist.T.shape}\")\n",
    "print(\"  full \" + \"match\" if np.allclose(ctx_to_sc_dist, sc_to_ctx_dist.T) else \"miss\")\n",
    "print(\"  uint8 \" + \"match\" if np.allclose(np.astype(ctx_to_sc_dist, np.uint8), np.astype(sc_to_ctx_dist.T, np.uint8)) else \"miss\")\n",
    "\"\"\"\n",
    "\n",
    "# Results in\n",
    "\"\"\"\n",
    "Compare SC-to-CTX part (25647, 59412) to part of the whole (25647, 59412)\n",
    "  full match\n",
    "  uint8 match\n",
    "Compare SC-to-SC part (25647, 25647) to part of the whole (25647, 25647)\n",
    "  full match\n",
    "  uint8 match\n",
    "Compare CTX-to-SC part (59412, 25647) to part of the whole (59412, 25647)\n",
    "  full match\n",
    "  uint8 match\n",
    "Compare CTX-to-SC part (59412, 25647) to transposed SC-to-CTX (59412, 25647)\n",
    "  full match\n",
    "  uint8 match\n",
    "\"\"\""
   ],
   "id": "b6f03f046a3d5133",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----\n",
    "\n",
    "## Put all cortical distances together\n",
    "\n",
    "----"
   ],
   "id": "30cc9f79c798ba5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# We've calculated most of the distance matrix piece-meal, and need to\n",
    "# fill in some missing sections with fake large values that will exceed\n",
    "# the distance threshold and cause removal of those connectivity values later.\n",
    "# Start pasting lh-lh and rh-rh distances into a complete distance matrix\n",
    "# where anything between lh and rh is \"large\".\n",
    "# The largest uint8 is 2^8 == 256, which is big enough to get masked later.\n",
    "# [ [ lh  ] [255s ] [lh-sc] ]\n",
    "# [ [255s ] [ rh  ] [rh-sc] ]\n",
    "# [ [sc-lh] [sc-rh] [ sc  ] ]\n",
    "\n",
    "mem_before = psutil.Process(os.getpid()).memory_info().rss\n",
    "\n",
    "# (3) Create two filler blocks\n",
    "top_mid_lh_rh = np.ones((py_lh.shape[0], py_rh.shape[1]), dtype=np.uint8) * 255\n",
    "mid_mid_rh_lh = np.ones((py_rh.shape[0], py_lh.shape[1]), dtype=np.uint8) * 255\n",
    "\n",
    "# Put complete distance matrix together with real and filler data\n",
    "py_complete = np.vstack([\n",
    "    np.hstack([py_lh, top_mid_lh_rh, sc_to_lh_dist.T, ]),\n",
    "    np.hstack([mid_mid_rh_lh, py_rh, sc_to_rh_dist.T, ]),\n",
    "    np.hstack([sc_to_lh_dist, sc_to_rh_dist, sc_to_sc_dist, ])  # bottom row of blocks\n",
    "])\n",
    "\n",
    "np.save(Path(save_to) / \"dist_complete.npy\", py_complete)\n",
    "\n",
    "mem_after = psutil.Process(os.getpid()).memory_info().rss\n",
    "print(f\"Mem before {mem_before / 1024 / 1024:0,.1f}MB; \"\n",
    "      f\"Mem after {mem_after / 1024 / 1024:0,.1f}MB; \"\n",
    "      f\"delta {(mem_after - mem_before) / 1024 / 1024:0,.1f}\")\n"
   ],
   "id": "74c43742bb656be6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load matlab-based distance matrix for comparison\n",
    "\n",
    "matlab_dist_file = h5py.File(matlab_outdir / \"DistanceMatrix.mat\", 'r')\n",
    "ml_complete = np.array(matlab_dist_file.get('D'), dtype=np.uint8)\n"
   ],
   "id": "48547d6a0713e4f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compare matlab's distance results to python's.\n",
    "# We know there are very few, << 1%, float representation differences\n",
    "# that were locked in rounding to uint8s. Everything else should match.\n",
    "mat_sections = [(\"lh\", 0, 29696), (\"rh\", 29696, 59412), (\"sc\", 59412, 85059), ]\n",
    "for (a_name, a_start, a_end) in mat_sections:\n",
    "    for (b_name, b_start, b_end) in mat_sections:\n",
    "        section_name = \"-\".join([a_name, b_name])\n",
    "        mat_a = py_complete[a_start:a_end, b_start:b_end]\n",
    "        mat_b = ml_complete[a_start:a_end, b_start:b_end]\n",
    "        print(f\"** Compare {section_name}: {mat_a.shape} v {mat_b.shape}\")\n",
    "        compare_mats(mat_a, mat_b,\n",
    "                     a_name=f\"python {section_name}\",\n",
    "                     b_name=f\"matlab {section_name}\",\n",
    "                     verbose=True, preview=False)\n"
   ],
   "id": "4cfbed02b971e6cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "id": "86324ce17c8f3462",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
